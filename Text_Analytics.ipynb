{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3YbW3w5fok2p"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def textfeatures(features):\n",
    "\tphrase=[]\n",
    "\tfor feature in list(features):\n",
    "\t\twords = \"\"\n",
    "# \t\tprint(\"feature\",feature,type(feature))\n",
    "\t\tfor word in feature.split(\",\"):\n",
    "\t\t\tword = word.replace(\" \",\"\")\n",
    "\t\t\tword = word.replace(\"'\",\"\")\n",
    "\t\t\tword = word.replace(\"[\",\"\")\n",
    "\t\t\tword = word.replace(\"]\",\"\")\n",
    "\t\t\twords += word + \" \"\n",
    "# \t\t\tprint(\"word\",word)\n",
    "\t\tphrase.append(words)\n",
    "# \t\tbreak\n",
    "\treturn phrase\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tdata = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/final_features.csv\").fillna(\"undefined\")\n",
    "\tlabels = data[\"author\"]\n",
    "\ttext = data[\"text\"]\n",
    "\t## text features\n",
    "\tnouns = data[\"nouns\"]\n",
    "\tnamed_ents = data[\"named_ents\"]\n",
    "\tverbs = data[\"verb\"]\n",
    "\tadjs = data[\"adj\"]\n",
    "\tnoun_phrases = data[\"noun_phrases\"]\n",
    "\n",
    "\t## count features\n",
    "\tcount_nouns = data[\"noun_tokens\"]\n",
    "\tcount_named_ents = data[\"entity_tokens\"]\n",
    "\tcount_verbs = data[\"verb_tokens\"]\n",
    "\tcount_adjs = data[\"adj_tokens\"]\n",
    "\tcount_noun_phrases = data[\"noun_phrases_tokens\"]\n",
    "\n",
    "\t## extra count features\n",
    "\tunique_words = data[\"num_unique_words\"]\n",
    "\tstopwords = data[\"num_stopwords\"]\n",
    "\tarticles = data[\"article\"]\n",
    "\tpunc = data[\"num_punctuations\"]\n",
    "\tmean_word_len = data[\"mean_word_len\"]\n",
    "\tnon_voc = data[\"n_non_voc\"]\n",
    "\n",
    "\tnoun_phrases = textfeatures(noun_phrases)\n",
    "\tnouns = textfeatures(nouns)\n",
    "\tverbs = textfeatures(verbs)\n",
    "\tnamed_ents = textfeatures(named_ents)\n",
    "\tadjs = textfeatures(adjs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FM2Ifkg6p97A"
   },
   "source": [
    "Vectorisation of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "gqrrlLvMp3yy",
    "outputId": "ee57a4d0-8219-4ff7-8989-ff34c961d25a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded\n",
      "de allocation\n"
     ]
    }
   ],
   "source": [
    "# TFIDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "# text = pd.DataFrame(tfidf.fit_transform(text).toarray())\n",
    "nouns = pd.DataFrame(tfidf.fit_transform(nouns).toarray())\n",
    "# verbs = pd.DataFrame(tfidf.fit_transform(verbs).toarray())\n",
    "# named_ents = pd.DataFrame(tfidf.fit_transform(named_ents).toarray())\n",
    "# adjs = pd.DataFrame(tfidf.fit_transform(adjs).toarray())\n",
    "# noun_phrases = pd.DataFrame(tfidf.fit_transform(noun_phrases).toarray())\n",
    "\n",
    "## ordinal encoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "labels = pd.DataFrame(OrdinalEncoder().fit_transform(labels.to_numpy().reshape(-1,1)))\n",
    "print(\"encoded\")\n",
    "\n",
    "## joining\n",
    "# X = pd.concat([count_nouns,count_named_ents,count_verbs,count_adjs,count_noun_phrases,\n",
    "#               unique_words,stopwords,articles,punc,mean_word_len,non_voc,\n",
    "#               nouns,named_ents,verbs])\n",
    "# print(\"joined\",X.shape)\n",
    "\n",
    "## de allocating memory\n",
    "# nouns = named_ents = verbs = adjs = count_nouns = count_named_ents = count_verbs = count_adjs = count_noun_phrases = unique_words = stopwords = articles = punc = mean_word_len = non_voc = 0\n",
    "print(\"de allocation\")\n",
    "\n",
    "## train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "steps = 25000\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(nouns, labels, test_size=0.1,shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HZpYL8WFp1kj"
   },
   "source": [
    "Training a model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iiMwjmmdt6AZ"
   },
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "skBeMBbOp0-Q"
   },
   "outputs": [],
   "source": [
    "## training a model\n",
    "# from sklearn.svm import SVC\n",
    "# svm = SVC(kernel = \"linear\",C=0.025, random_state = 13)\n",
    "# svm.fit(X_train,Y_train)\n",
    "# y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTCzE6qDt8VA"
   },
   "source": [
    "Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "nUrN6qcDWJLJ",
    "outputId": "155cd567-092a-49d4-c929-def1b7c84fc2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_ridge.py:940: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import RidgeClassifier\n",
    "# clf = RidgeClassifier()\n",
    "# clf.fit(X_train,Y_train)\n",
    "# Y_predict = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xw4UodzpCB6o"
   },
   "source": [
    "\n",
    "LBGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WoOQgQwWCCe3"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "mdl = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=63, max_depth=-1, learning_rate=0.1, n_estimators=100)\n",
    "mdl.fit(X_train, Y_train.values.ravel())\n",
    "Y_predict = mdl.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "FCxpXqc7WiPf",
    "outputId": "050860a7-a8ed-4ca9-8663-b563eadf92db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nouns] Accurracy 0.503216583273767 Precision recall (array([0.53050109, 0.61466165, 0.56047198, 0.31940299]), array([0.63001294, 0.59025271, 0.61889251, 0.24970828]), array([0.57599054, 0.60220994, 0.58823529, 0.28028815]), array([773, 554, 614, 857])) confusion matrix [[487  30  61 195]\n",
      " [ 73 327  23 131]\n",
      " [ 80  24 380 130]\n",
      " [278 151 214 214]] \n"
     ]
    }
   ],
   "source": [
    "## confusion matrix\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix,accuracy_score,precision_recall_fscore_support\n",
    "confMatrix = confusion_matrix(Y_test,Y_predict)\n",
    "accuracy_noun = accuracy_score(Y_test,Y_predict)\n",
    "precision_recall_fscore = precision_recall_fscore_support(Y_test,Y_predict)\n",
    "\n",
    "print(\"[nouns] Accurracy {} Precision recall {} confusion matrix {} \".format(accuracy_noun,precision_recall_fscore,confMatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sDnaO3zHWqRb"
   },
   "source": [
    "Pure test SET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOly26aJWolA"
   },
   "outputs": [],
   "source": [
    "## testing previous set\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix,accuracy_score,precision_recall_fscore_support\n",
    "Y_test_predict = clf.predict(nouns.iloc[steps:,:])\n",
    "Y_test_final = labels.iloc[steps:,:]\n",
    "\n",
    "confMatrix = confusion_matrix(Y_test_final,Y_test_predict)\n",
    "accuracy_noun = accuracy_score(Y_test_final,Y_test_predict)\n",
    "precision_recall_fscore = precision_recall_fscore_support(Y_test_final,Y_test_predict)\n",
    "\n",
    "\n",
    "print(\"[nouns][TEST] Accurracy {} Precision recall {} confusion matrix {} \".format(accuracy_noun,precision_recall_fscore,confMatrix))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Text Analytics.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
